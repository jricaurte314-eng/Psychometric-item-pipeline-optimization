# ğŸ§® Psychometric Item Pipeline & Optimization â€“ AWS Â· Python Â· Bees Algorithm

## ğŸ¯ Overview  

This project focused on building an **end-to-end data pipeline and analytical workflow** for psychometric item analysis and optimization.  
The main objective was to process raw assessment data stored in **AWS**, clean and score responses, generate **exploratory statistics and psychometric indicators**, and use an **optimization algorithm (Bees Algorithm)** to create item versions that maximize explained variance.  

The project integrates **data engineering, statistical analysis, and algorithmic optimization**, providing a scalable foundation for psychometric evaluation and test versioning.  

---

## âš™ï¸ Project Workflow  

### **1ï¸âƒ£ Data Extraction Pipeline (AWS)**
- Built a **data pipeline** to query and extract assessment data stored in an **AWS S3 bucket**.  
- Established connection credentials and query logic for scheduled data retrieval.  
- Automated file ingestion and transformation into a standardized format for analysis.  

ğŸ§° *Tools:* Python (boto3, pandas) Â· AWS S3 Â· SQLAlchemy  

---

### **2ï¸âƒ£ Data Cleaning & Preprocessing**
- Performed a **deep cleaning process** to handle missing responses, invalid records, and inconsistent IDs.  
- Applied normalization of item responses and scoring scales for comparability.  
- Generated clean, structured datasets ready for psychometric computation.  

ğŸ§° *Tools:* Python (pandas, numpy) Â· Excel (validation templates)  

---

### **3ï¸âƒ£ Dataset Scoring & Statistical Exploration**
- Implemented scoring functions in **Python** to calculate total and subscale scores per participant.  
- Conducted **exploratory data analysis (EDA)** to identify distributional characteristics, outliers, and response patterns.  
- Computed **item-level descriptive statistics** (mean, SD, skewness, kurtosis) for quality control.  

ğŸ§° *Tools:* Python (pandas, scipy, matplotlib)  

---

### **4ï¸âƒ£ Psychometric Indicators**
- Calculated **item difficulty** and **discrimination indices**, evaluating item performance across the dataset.  
- Grouped participants by performance levels (low, medium, high) to support **item response validation**.  
- Provided interpretable metrics to support future test calibration.  

ğŸ§  *Key Concept:* Item difficulty and discrimination indices help identify the precision and validity of assessment instruments.  

ğŸ§° *Tools:* Python Â· numpy Â· scipy.stats  

---

### **5ï¸âƒ£ Test Versioning & Optimization (Bees Algorithm)**
- Designed and implemented an **optimization routine** using the **Bees Algorithm** to generate test versions with different item counts (24 and 48 items).  
- Objective: **maximize explained variance** while maintaining internal consistency and balanced item representation.  
- Evaluated convergence criteria and reproducibility of optimized test forms.  

ğŸ§  *Algorithm Insight:* The Bees Algorithm mimics foraging behavior to explore solution spaces efficiently, ideal for multi-objective psychometric optimization.  

ğŸ§° *Tools:* Python (custom Bees Algorithm implementation) Â· matplotlib  

---

## ğŸ“Š Results & Impact  

- Built a **reusable, automated psychometric analysis pipeline** integrated with AWS data sources.  
- Generated **clean, validated datasets** and item performance metrics for stakeholders.  
- Produced **optimized test versions (24 & 48 items)** with improved variance explanation and reliability.  
- Enabled future integration of automated test assembly processes using AI-driven optimization.  

---

## ğŸ§° Tech Stack  

| Category | Tools & Technologies |
|-----------|---------------------|
| Data Engineering | Python (boto3, pandas) Â· AWS S3 Â· SQLAlchemy |
| Data Cleaning | Pandas Â· Numpy Â· Excel Templates |
| Psychometric Analysis | Python (scipy.stats, matplotlib) |
| Optimization | Bees Algorithm (custom implementation) |
| Reporting | Power BI Â· Python Visualizations |

---

## ğŸ“ Folder Structure  

```markdown
psychometric_item_pipeline/
â”‚
â”œâ”€â”€ ğŸ“˜ README.md                         # Project documentation
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ 01_data_extraction_aws.ipynb     # Pipeline connection and queries to AWS
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb           # Data preprocessing and validation
â”‚   â”œâ”€â”€ 03_scoring_eda.ipynb             # Scoring logic and exploratory statistics
â”‚   â”œâ”€â”€ 04_item_analysis.ipynb           # Difficulty & discrimination indices
â”‚   â”œâ”€â”€ 05_bees_algorithm_optimization.ipynb # Optimization routine for item selection
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ aws_pipeline.py                  # AWS data extraction scripts
â”‚   â”œâ”€â”€ cleaning_utils.py                # Data cleaning helper functions
â”‚   â”œâ”€â”€ scoring_functions.py             # Item scoring and metrics
â”‚   â”œâ”€â”€ bees_algorithm.py                # Bees Algorithm optimization logic
â”‚   â”œâ”€â”€ item_analysis.py                 # Item difficulty/discrimination calculations
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw_data/                        # Extracted data from AWS
â”‚   â”œâ”€â”€ cleaned_data.csv                 # Cleaned dataset
â”‚   â”œâ”€â”€ item_metrics.csv                 # Item-level indicators
â”‚   â””â”€â”€ optimized_versions.csv           # Optimized 24/48-item versions
â”‚
â”œâ”€â”€ ğŸ“‚ results/
â”‚   â”œâ”€â”€ bees_convergence_plot.png        # Optimization convergence visualization
â”‚   â”œâ”€â”€ item_difficulty_distribution.png # Histogram of item difficulties
â”‚   â”œâ”€â”€ group_performance_summary.pdf    # Group-level performance report
â”‚
â””â”€â”€ ğŸ“‚ docs/
    â”œâ”€â”€ bees_algorithm_explained.md      # Technical explanation of algorithm
    â”œâ”€â”€ psychometric_formulas.md         # Difficulty/discrimination equations
    â””â”€â”€ lessons_learned.md
